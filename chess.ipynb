{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e1a63d",
   "metadata": {},
   "source": [
    "## Install relevant dependencies\n",
    "I make the assumption that Pytorch is already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7730e-c50c-4a0e-b1f5-c8028ab7d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-chess\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19402cf7",
   "metadata": {},
   "source": [
    "## Download chess game data\n",
    "Can skip this step if your own pgns to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec8fd6-a98e-48de-982b-376d53141d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://database.lichess.org/standard/lichess_db_standard_rated_2013-01.pgn.zst --output games.pgn.zst\n",
    "!zstd --decompress games.pgn.zst\n",
    "\n",
    "# !mkdir pgns/ # uncomment if pgns dir does not exist\n",
    "!mv games.pgn pgns/\n",
    "!rm games.pgn.zst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404005b",
   "metadata": {},
   "source": [
    "## Create list of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3673feb-7f02-43f2-aba9-3c8353422353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.pgn\n",
    "\n",
    "pgn = open(\"pgns/games.pgn\", \"r\", encoding=\"utf-8\")\n",
    "\n",
    "all_games= []\n",
    "\n",
    "# while True: \n",
    "for i in range(5000): # increase this limit for a better model\n",
    "    game = chess.pgn.read_game(pgn)\n",
    "    if game is None:\n",
    "        break  # End of games\n",
    "        \n",
    "    all_games.append(game)\n",
    "\n",
    "pgn.close()\n",
    "print(f\"{len(all_games)} games parsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d93bd",
   "metadata": {},
   "source": [
    "## Create list of distinct chess positions\n",
    "Goal of this is to create diverse set of chess FENs that can be used to create the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55cbb9-2620-476e-bd85-24b8231495da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_positions = set()\n",
    "\n",
    "for game in all_games:\n",
    "    board = game.board()\n",
    "    moves = list(game.mainline_moves())\n",
    "    positions = []\n",
    "    \n",
    "    for move in moves:\n",
    "        board.push(move)\n",
    "        positions.append(board.fen())\n",
    "    \n",
    "    random_positions = random.sample(positions, min(10, len(moves)) // 7)\n",
    "    all_positions.update(random_positions)\n",
    "\n",
    "all_positions = list(all_positions)\n",
    "print(f\"{len(all_positions)} unique positions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f4eef",
   "metadata": {},
   "source": [
    "## Define functions to convert between tensor and FEN string\n",
    "This will let us encode chess positions in a way the NNs can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "piece_to_idx = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "                'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "\n",
    "def pos_to_tensor(fen, device=\"cpu\"):\n",
    "    parts = fen.split(\" \")\n",
    "    wtm = parts[1] == \"w\"\n",
    "    castling_rights = parts[2]\n",
    "\n",
    "    board = chess.Board(fen)\n",
    "    tensor = torch.zeros(15, 8, 8, device=device)\n",
    "\n",
    "    for row in range(8): \n",
    "        for col in range(8):\n",
    "            sqr = chess.square(col, 7 - row)\n",
    "            piece = board.piece_at(sqr)\n",
    "            if piece != None:\n",
    "                p = piece.symbol()\n",
    "                idx = piece_to_idx[p]\n",
    "                tensor[idx, row, col] = 1 if p.isupper() else -1\n",
    "                  \n",
    "    # Encode castling rights\n",
    "    if 'K' in castling_rights:\n",
    "        tensor[12, 0, 0] = 1\n",
    "    if 'Q' in castling_rights:\n",
    "        tensor[12, 0, 7] = 1\n",
    "    if 'k' in castling_rights:\n",
    "        tensor[13, 7, 0] = -1  \n",
    "    if 'q' in castling_rights:\n",
    "        tensor[13, 7, 7] = -1\n",
    "          \n",
    "    # Encode side to move\n",
    "    tensor[14] = 1 if wtm else -1\n",
    "      \n",
    "    return tensor\n",
    "\n",
    "def tensor_to_pos(tensor):\n",
    "    board = chess.Board(None)\n",
    "    piece_symbols = list(piece_to_idx.keys())\n",
    "    \n",
    "    # Decode the board pieces\n",
    "    for idx, piece_symbol in enumerate(piece_symbols[:12]):\n",
    "        mask = tensor[idx].abs() > 0\n",
    "        positions = mask.nonzero(as_tuple=True)\n",
    "        for row, col in zip(*positions):\n",
    "            square = chess.square(col, 7 - row)\n",
    "            board.set_piece_at(square, chess.Piece.from_symbol(piece_symbol))\n",
    "    \n",
    "    # Decode castling rights\n",
    "    castling_rights = ''\n",
    "    if tensor[12, 0, 0] == 1:\n",
    "        castling_rights += 'K'\n",
    "    if tensor[12, 0, 7] == 1:\n",
    "        castling_rights += 'Q'\n",
    "    if tensor[13, 7, 0] == -1:\n",
    "        castling_rights += 'k'\n",
    "    if tensor[13, 7, 7] == -1:\n",
    "        castling_rights += 'q'\n",
    "    board.set_castling_fen(castling_rights)\n",
    "    \n",
    "    # Decode side to move\n",
    "    side_to_move = 'w' if tensor[14].mean() > 0 else 'b'\n",
    "    board.turn = True if side_to_move == 'w' else False\n",
    "    \n",
    "    return board.fen()\n",
    "    \n",
    "print(f\"Shape of encoded chess position tensor: {pos_to_tensor(all_positions[0]).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2cc77",
   "metadata": {},
   "source": [
    "## Set pytorch device to cuda if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e84bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory._record_memory_history()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(\"cpu\")\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660724dc",
   "metadata": {},
   "source": [
    "## Create datasets for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79662dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PositionDataset(Dataset):\n",
    "  def __init__(self, tensors):\n",
    "        self.tensors = tensors\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.tensors)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "        return self.tensors[idx]\n",
    "\n",
    "tensors = [pos_to_tensor(pos, device) for pos in all_positions]\n",
    "random.shuffle(tensors)\n",
    "\n",
    "# Calculate the indices for splitting\n",
    "total_tensors = len(tensors)\n",
    "train_end = int(total_tensors * 0.8)\n",
    "val_end = int(total_tensors * 0.9)\n",
    "\n",
    "# Split the tensors into train, validation, and test sets\n",
    "train_tensors = tensors[:train_end]\n",
    "val_tensors = tensors[train_end:val_end]\n",
    "test_tensors = tensors[val_end:]\n",
    "\n",
    "# Create datasets for each split\n",
    "train_dataset = PositionDataset(train_tensors)\n",
    "val_dataset = PositionDataset(val_tensors)\n",
    "test_dataset = PositionDataset(test_tensors)\n",
    "\n",
    "print(f\"len training set: {len(train_dataset)}\")\n",
    "print(f\"len validation set: {len(val_dataset)}\")\n",
    "print(f\"len test set: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2360cb",
   "metadata": {},
   "source": [
    "## Define the structure of the NN\n",
    "We are training an autoencoder that will learn to deconstruct, then reconstruct chess positions.\\\n",
    "Once trained, we can use the encoder to generate our embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea35a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hyperparams):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        channels = hyperparams[\"position_channels\"]\n",
    "        n_embed = hyperparams[\"n_embed\"]\n",
    "        filters = hyperparams[\"filters\"]\n",
    "        fc_size = hyperparams[\"fc_size\"]\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, filters, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(filters, filters * 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(filters * 2, filters * 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(filters * 4 * 1 * 1, fc_size)\n",
    "        self.fc2 = nn.Linear(fc_size, n_embed)  # Compressed representation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))  \n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hyperparams):        \n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        channels = hyperparams[\"position_channels\"]\n",
    "        n_embed = hyperparams[\"n_embed\"]\n",
    "        filters = hyperparams[\"filters\"]\n",
    "        fc_size = hyperparams[\"fc_size\"]\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(n_embed, fc_size)\n",
    "        self.fc2 = nn.Linear(fc_size, filters * 4 * 1 * 1)\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(filters * 4 , 1, 1))\n",
    "        self.deconv1 = nn.ConvTranspose2d(filters * 4, filters * 2, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(filters * 2, filters, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(filters, channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.unflatten(x)\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = self.deconv3(x)\n",
    "        return x\n",
    "\n",
    "class PositionAutoEncoder(nn.Module):\n",
    "    def __init__(self, hyperparams):\n",
    "        super(PositionAutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder(hyperparams)\n",
    "        self.decoder = Decoder(hyperparams)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def embed(self, x):\n",
    "        code = self.encoder(x)\n",
    "        return code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b6c97",
   "metadata": {},
   "source": [
    "## Define model hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"n_epochs\": 50,\n",
    "    \"learning_rate\": 17e-4,\n",
    "    \"dropout_rate\": 0,\n",
    "    \"position_channels\": 15,\n",
    "    \"n_embed\": 128,\n",
    "    \"filters\": 32,\n",
    "    \"fc_size\": 256,\n",
    "    \"version\": 6\n",
    "}\n",
    "\n",
    "batch_size = hyperparams[\"batch_size\"]\n",
    "n_epochs = hyperparams[\"n_epochs\"]\n",
    "learning_rate = hyperparams[\"learning_rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caab68f",
   "metadata": {},
   "source": [
    "## Initialize the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0173f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW, lr_scheduler\n",
    "\n",
    "# init dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#init model\n",
    "model = PositionAutoEncoder(hyperparams)\n",
    "model.to(device)\n",
    "\n",
    "# init optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "num_params = sum(p.numel() for p in model.parameters())/1e6\n",
    "print(f\"{num_params:.2f}M parameters\")\n",
    "\n",
    "# init lr scheduler\n",
    "num_training_steps = n_epochs * len(train_loader)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer=optimizer, max_lr=learning_rate, total_steps=num_training_steps)\n",
    "print(f\"training iterations: {num_training_steps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961daaa",
   "metadata": {},
   "source": [
    "## Run the training loop\n",
    "We train by minimizing MSE loss on the reconstructed posittion encoding.\\\n",
    "Validation loss is calculated after each epoch to ensure learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba977d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # switch model to training mode\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    print(f\"finished epcoh: {epoch}\")\n",
    "    with torch.no_grad():\n",
    "        # evaluate validation loss\n",
    "        model.eval() # switch model to evaluation mode\n",
    "        losses = torch.zeros(len(val_loader), device=device)\n",
    "        k = 0\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, batch)\n",
    "                \n",
    "            losses[k] = loss.item()\n",
    "            k += 1\n",
    "\n",
    "        avg_val_loss = losses.mean()\n",
    "        # -----------------------------\n",
    "        \n",
    "        # evaluate training loss\n",
    "        losses =  torch.zeros(len(train_loader), device=device)\n",
    "        k = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, batch)\n",
    "                \n",
    "            losses[k] = loss.item()\n",
    "            k += 1\n",
    "            \n",
    "            if(k == len(train_loader)):\n",
    "                break\n",
    "        \n",
    "        avg_train_loss = losses.mean()\n",
    "        # ------------------------------\n",
    "        print(f\"learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "        print(f\"val loss: {avg_val_loss}\")\n",
    "        print(f\"train loss: {avg_train_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94aebd",
   "metadata": {},
   "source": [
    "## Save the trained model weights and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82934b2-286a-43e8-9159-3c48b13ae737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir models  # uncomment to create models/ dir\n",
    "checkpoint = {\n",
    "    \"model\": model.state_dict(),\n",
    "    \"train_set\": train_dataset,\n",
    "    \"val_set\": val_dataset,\n",
    "    \"test_set\": test_dataset,\n",
    "    \"hyperparameters\": hyperparams\n",
    "}\n",
    "torch.save(checkpoint, f\"models/v0.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fbdd8",
   "metadata": {},
   "source": [
    "## Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkp = torch.load(\"models/v0.pt\")\n",
    "emb_model = PositionAutoEncoder(chkp[\"hyperparameters\"]).to(device)\n",
    "emb_model.eval()\n",
    "emb_model.load_state_dict(chkp[\"model\"])\n",
    "\n",
    "train_dataset = chkp[\"train_set\"]\n",
    "val_dataset = chkp[\"val_set\"]\n",
    "test_dataset = chkp[\"test_set\"]\n",
    "embed_data = list(train_dataset + val_dataset + test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1c8eb",
   "metadata": {},
   "source": [
    "## Embed collection of chess positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a3d3c-d08e-4f72-a690-d856db82c644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches = [embed_data[i:i + 256] for i in range(0, len(embed_data), 256)]\n",
    "embeds = torch.cat([emb_model.embed(torch.stack(batch)) for batch in batches]).unsqueeze(1)\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c30e0",
   "metadata": {},
   "source": [
    "## Seacrh similar positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6da8ec-b476-484c-835e-e56a8e3ecbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# embed a query position\n",
    "query = emb_model.embed(test_dataset[0].unsqueeze(0)).unsqueeze(0)\n",
    "\n",
    "# calculate similarities and find top matches\n",
    "similarities = F.cosine_similarity(embeds, query, dim=2)\n",
    "top_matches = torch.topk(similarities, 10, dim=0)\n",
    "\n",
    "# print(top_matches.values)\n",
    "\n",
    "# convert matches to FEN strings\n",
    "top_tensors = torch.stack(list(embed_data))[top_matches.indices].squeeze(1)\n",
    "top_tensors = list(torch.split(top_tensors, 1, dim=0))\n",
    "positions = [tensor_to_pos(t.squeeze(0)) for t in top_tensors]\n",
    "query_pos = tensor_to_pos(test_dataset[0])\n",
    "\n",
    "print(f\"query position: {query_pos}\")\n",
    "print(f\"similar positions: {positions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d10cd",
   "metadata": {},
   "source": [
    "## Inspect similar positions\n",
    "Pass a FEN string to chess.Board() to view it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9593e8-d768-43ce-b28d-dee61a94c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "chess.Board(query_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e02f0e-3e5b-4f40-9dd9-ef60e029428b",
   "metadata": {},
   "outputs": [],
   "source": [
    " chess.Board(positions[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
